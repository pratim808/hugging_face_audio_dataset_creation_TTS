{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9695192,
          "sourceType": "datasetVersion",
          "datasetId": 5927865
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Dataset_English_techn",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratim808/hugging_face_audio_dataset_creation_TTS/blob/main/Dataset_English_techn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "IP-WubzedvSJ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "manaspkundu_youtube_links_1_path = kagglehub.dataset_download('manaspkundu/youtube-links-1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "dVtdPulxdvSM"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-10-22T17:35:27.271869Z",
          "iopub.execute_input": "2024-10-22T17:35:27.27224Z",
          "iopub.status.idle": "2024-10-22T17:35:27.64123Z",
          "shell.execute_reply.started": "2024-10-22T17:35:27.272203Z",
          "shell.execute_reply": "2024-10-22T17:35:27.640321Z"
        },
        "trusted": true,
        "id": "VDaxt78KdvSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T17:35:27.643332Z",
          "iopub.execute_input": "2024-10-22T17:35:27.64458Z",
          "iopub.status.idle": "2024-10-22T17:36:01.802833Z",
          "shell.execute_reply.started": "2024-10-22T17:35:27.644524Z",
          "shell.execute_reply": "2024-10-22T17:36:01.801609Z"
        },
        "trusted": true,
        "id": "57oTr5pCdvSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spleeter\n",
        "!pip install yt-dlp\n",
        "!pip install pydub"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T17:36:28.869957Z",
          "iopub.execute_input": "2024-10-22T17:36:28.870679Z",
          "iopub.status.idle": "2024-10-22T17:38:21.306961Z",
          "shell.execute_reply.started": "2024-10-22T17:36:28.87063Z",
          "shell.execute_reply": "2024-10-22T17:38:21.305639Z"
        },
        "trusted": true,
        "id": "_2kbiJiQdvSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spleeter\n",
        "from __future__ import unicode_literals\n",
        "import yt_dlp\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from termcolor import colored\n",
        "import os\n",
        "import whisper"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T17:38:21.309043Z",
          "iopub.execute_input": "2024-10-22T17:38:21.309351Z",
          "iopub.status.idle": "2024-10-22T17:38:25.748157Z",
          "shell.execute_reply.started": "2024-10-22T17:38:21.309318Z",
          "shell.execute_reply": "2024-10-22T17:38:25.747135Z"
        },
        "trusted": true,
        "id": "rUEL393hdvSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_audio(audio_file):\n",
        "    \"\"\"\n",
        "    Corrects the channels, sample rate, and sample width of the audios.\n",
        "    Replaces the original audio file with the one generated.\n",
        "    \"\"\"\n",
        "    sound = AudioSegment.from_file(audio_file)\n",
        "    sound = sound.set_frame_rate(16000)\n",
        "    sound = sound.set_channels(1)\n",
        "    sound = sound.set_sample_width(2) # 2 corresponds to 16-bit sample width in Pydub\n",
        "    sound.export(audio_file, format =\"wav\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T17:38:31.590733Z",
          "iopub.execute_input": "2024-10-22T17:38:31.591814Z",
          "iopub.status.idle": "2024-10-22T17:38:31.598149Z",
          "shell.execute_reply.started": "2024-10-22T17:38:31.59177Z",
          "shell.execute_reply": "2024-10-22T17:38:31.597056Z"
        },
        "trusted": true,
        "id": "BnjVrsAVdvSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ydl_opts = {\n",
        "    \"format\": \"bestaudio/best\",\n",
        "    \"audio-format\": \"wav\",\n",
        "    \"outtmpl\": \"audio.wav\",\n",
        "    \"noplaylist\" : True\n",
        "} # customizing the downloaded audio for our needs\n",
        "link_num = 1 # iterates over the links in the TXT file\n",
        "links_file = \"/kaggle/input/youtube-links-1/1_links.txt\" # File containing links to YouTube videos"
      ],
      "metadata": {
        "id": "v-BSbPbHdvST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ydl_opts = {\n",
        "    \"format\": \"bestaudio/best\",\n",
        "    \"audio-format\": \"wav\",\n",
        "    \"outtmpl\": \"audio.wav\",\n",
        "    \"noplaylist\" : True\n",
        "} # customizing the downloaded audio for our needs\n",
        "link_num = 25 # iterates over the links in the TXT file\n",
        "links_file = \"/kaggle/input/youtube-links-1/1_links.txt\" # File containing links to YouTube videos"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T18:45:13.276519Z",
          "iopub.execute_input": "2024-10-22T18:45:13.27744Z",
          "iopub.status.idle": "2024-10-22T18:45:13.282117Z",
          "shell.execute_reply.started": "2024-10-22T18:45:13.277399Z",
          "shell.execute_reply": "2024-10-22T18:45:13.281106Z"
        },
        "trusted": true,
        "id": "QWz4Pw2OdvSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Transcribe the audio using Whisper\n",
        "model = whisper.load_model(\"base\")  # Load the Whisper model (you can choose different sizes)\n",
        "\n",
        "def transcribe_audio(wav_file):\n",
        "    \"\"\"Transcribes audio from a WAV file using the Whisper model and saves the transcript.\"\"\"\n",
        "    result = model.transcribe(wav_file)\n",
        "\n",
        "    # Generate the text file name with the same base name as the audio file\n",
        "    transcript_file = os.path.splitext(wav_file)[0] + \".txt\"\n",
        "\n",
        "    with open(transcript_file, \"w\") as f:\n",
        "        f.write(result[\"text\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T18:45:17.101335Z",
          "iopub.execute_input": "2024-10-22T18:45:17.101763Z",
          "iopub.status.idle": "2024-10-22T18:45:18.584644Z",
          "shell.execute_reply.started": "2024-10-22T18:45:17.101724Z",
          "shell.execute_reply": "2024-10-22T18:45:18.583767Z"
        },
        "trusted": true,
        "id": "Bzfz81BedvSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''def create_audio_transcription_pair(wav_file, transcript_file):\n",
        "    \"\"\"\n",
        "    Creates a dictionary with audio data and transcription from the given files.\n",
        "    \"\"\"\n",
        "    # Load audio using librosa\n",
        "    audio_array, sampling_rate = librosa.load(wav_file, sr=16000)  # Set sampling rate to 16000\n",
        "\n",
        "    with open(transcript_file, \"r\") as f:\n",
        "        transcription = f.read()\n",
        "\n",
        "    return {\n",
        "        'audio': {\n",
        "            'path': wav_file,\n",
        "            'array': audio_array.astype(np.float32),  # Convert to float32\n",
        "            'sampling_rate': sampling_rate\n",
        "        },\n",
        "        'transcription': transcription\n",
        "    }'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T17:36:16.677176Z",
          "iopub.status.idle": "2024-10-22T17:36:16.677602Z",
          "shell.execute_reply.started": "2024-10-22T17:36:16.677371Z",
          "shell.execute_reply": "2024-10-22T17:36:16.677392Z"
        },
        "trusted": true,
        "id": "yu8yTfSddvSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(links_file) as fp:\n",
        "    for link in fp:\n",
        "        print(\"\\nStarting processing for link number \", link_num)\n",
        "\n",
        "        # Step 1: Extract and download the audio\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:  # Replace YoutubeDL with yt_dlp.YoutubeDL\n",
        "                                 ydl.download([link])\n",
        "        except Exception as e:\n",
        "            print(colored(\"Link number {} cannot be downloaded. Exception: {}\".format(link_num, e), 'red'))\n",
        "            continue # continue with the next link in the file\n",
        "\n",
        "        # Step 2: Separate voice from the audio\n",
        "        !spleeter separate -p spleeter:2stems -o output \"/kaggle/working/audio.wav\"\n",
        "\n",
        "        # Step 3: Adjust the sampling rate, sample width, and channels\n",
        "        convert_audio(\"/kaggle/working/output/audio/vocals.wav\")\n",
        "\n",
        "        # Step 4: Split into smaller parts\n",
        "        # Step 4: Split into 4-second parts\n",
        "        sound_file = AudioSegment.from_wav(\"/kaggle/working/output/audio/vocals.wav\")\n",
        "        sub_chunk_length = 4000  # 4 seconds in milliseconds\n",
        "\n",
        "        # Calculate the number of sub-chunks\n",
        "        num_sub_chunks = len(sound_file) // sub_chunk_length\n",
        "\n",
        "        print(\"exporting files for link number: \", link_num)\n",
        "        os.mkdir(str(link_num))  # making folder named after link number\n",
        "\n",
        "        for j in range(num_sub_chunks):\n",
        "            start_time = j * sub_chunk_length\n",
        "            end_time = (j + 1) * sub_chunk_length\n",
        "            sub_chunk = sound_file[start_time:end_time]\n",
        "            out_file = \"{0}/{0}_{1}.wav\".format(link_num, j + 1)  # Start with 1\n",
        "            sub_chunk.export(out_file, format=\"wav\")\n",
        "            # Transcribe each 4-second chunk\n",
        "            transcribe_audio(out_file)\n",
        "\n",
        "        # Handle remaining audio\n",
        "        remaining_length = len(sound_file) % sub_chunk_length # This line and the following were improperly indented\n",
        "        if remaining_length > 0:\n",
        "            start_time = num_sub_chunks * sub_chunk_length\n",
        "            sub_chunk = sound_file[start_time:]\n",
        "            out_file = \"{0}/{0}_{1}.wav\".format(link_num, num_sub_chunks + 1)\n",
        "            sub_chunk.export(out_file, format=\"wav\")\n",
        "            # Transcribe each 4-second chunk\n",
        "            transcribe_audio(out_file)\n",
        "        link_num += 1\n",
        "\n",
        "        # deleting the redundant files gnerated for previous link to save space\n",
        "        !rm -rf /kaggle/working/output\n",
        "        !rm /kaggle/working/audio.wav"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T17:40:24.557537Z",
          "iopub.execute_input": "2024-10-22T17:40:24.558552Z",
          "iopub.status.idle": "2024-10-22T18:35:09.172871Z",
          "shell.execute_reply.started": "2024-10-22T17:40:24.558507Z",
          "shell.execute_reply": "2024-10-22T18:35:09.171369Z"
        },
        "trusted": true,
        "id": "-VBrJrKydvSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(links_file) as fp:\n",
        "    for link in fp:\n",
        "        print(\"\\nStarting processing for link number \", link_num)\n",
        "\n",
        "        # Step 1: Extract and download the audio\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:  # Replace YoutubeDL with yt_dlp.YoutubeDL\n",
        "                                 ydl.download([link])\n",
        "        except Exception as e:\n",
        "            print(colored(\"Link number {} cannot be downloaded. Exception: {}\".format(link_num, e), 'red'))\n",
        "            continue # continue with the next link in the file\n",
        "\n",
        "        # Step 2: Separate voice from the audio\n",
        "        !spleeter separate -p spleeter:2stems -o output \"/kaggle/working/audio.wav\"\n",
        "\n",
        "        # Step 3: Adjust the sampling rate, sample width, and channels\n",
        "        convert_audio(\"/kaggle/working/output/audio/vocals.wav\")\n",
        "\n",
        "        # Step 4: Split into smaller parts\n",
        "        # Step 4: Split into 4-second parts\n",
        "        sound_file = AudioSegment.from_wav(\"/kaggle/working/output/audio/vocals.wav\")\n",
        "        sub_chunk_length = 4000  # 4 seconds in milliseconds\n",
        "\n",
        "        # Calculate the number of sub-chunks\n",
        "        num_sub_chunks = len(sound_file) // sub_chunk_length\n",
        "\n",
        "        print(\"exporting files for link number: \", link_num)\n",
        "        os.mkdir(str(link_num))  # making folder named after link number\n",
        "\n",
        "        for j in range(num_sub_chunks):\n",
        "            start_time = j * sub_chunk_length\n",
        "            end_time = (j + 1) * sub_chunk_length\n",
        "            sub_chunk = sound_file[start_time:end_time]\n",
        "            out_file = \"{0}/{0}_{1}.wav\".format(link_num, j + 1)  # Start with 1\n",
        "            sub_chunk.export(out_file, format=\"wav\")\n",
        "            # Transcribe each 4-second chunk\n",
        "            transcribe_audio(out_file)\n",
        "\n",
        "        # Handle remaining audio\n",
        "        remaining_length = len(sound_file) % sub_chunk_length # This line and the following were improperly indented\n",
        "        if remaining_length > 0:\n",
        "            start_time = num_sub_chunks * sub_chunk_length\n",
        "            sub_chunk = sound_file[start_time:]\n",
        "            out_file = \"{0}/{0}_{1}.wav\".format(link_num, num_sub_chunks + 1)\n",
        "            sub_chunk.export(out_file, format=\"wav\")\n",
        "            # Transcribe each 4-second chunk\n",
        "            transcribe_audio(out_file)\n",
        "        link_num += 1\n",
        "\n",
        "        # deleting the redundant files gnerated for previous link to save space\n",
        "        !rm -rf /kaggle/working/output\n",
        "        !rm /kaggle/working/audio.wav"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T18:45:36.36843Z",
          "iopub.execute_input": "2024-10-22T18:45:36.368836Z",
          "iopub.status.idle": "2024-10-22T19:21:21.016117Z",
          "shell.execute_reply.started": "2024-10-22T18:45:36.368797Z",
          "shell.execute_reply": "2024-10-22T19:21:21.014755Z"
        },
        "trusted": true,
        "id": "b_if0cuEdvSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "def create_audio_transcription_pair(wav_file, transcript_file):\n",
        "    \"\"\"\n",
        "    Creates a dictionary with audio data and transcription from the given files.\n",
        "    \"\"\"\n",
        "    # Load audio using librosa\n",
        "    audio_array, sampling_rate = librosa.load(wav_file, sr=16000)  # Set sampling rate to 16000\n",
        "\n",
        "    with open(transcript_file, \"r\") as f:\n",
        "        transcription = f.read()\n",
        "\n",
        "    return {\n",
        "        'audio': {\n",
        "            'path': wav_file,\n",
        "            'array': audio_array.tolist(),  # Convert to list for JSON serialization\n",
        "            'sampling_rate': sampling_rate\n",
        "        },\n",
        "        'transcription': transcription\n",
        "    }\n",
        "\n",
        "def process_folder(folder_path, output_folder):\n",
        "    \"\"\"\n",
        "    Processes a folder containing .wav and .txt files to create audio-transcription pairs\n",
        "    and saves the output to a specified folder.\n",
        "    \"\"\"\n",
        "    audio_transcription_pairs = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            wav_file = os.path.join(folder_path, filename)\n",
        "            transcript_file = os.path.join(folder_path, filename.replace(\".wav\", \".txt\"))\n",
        "            if os.path.exists(transcript_file):\n",
        "                pair = create_audio_transcription_pair(wav_file, transcript_file)\n",
        "                audio_transcription_pairs.append(pair)\n",
        "            else:\n",
        "                print(f\"Warning: No corresponding transcript found for {filename}\")\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Save the pairs to a JSON file\n",
        "    output_file = os.path.join(output_folder, \"audio_transcription_pairs.json\")\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(audio_transcription_pairs, f, indent=4)\n",
        "\n",
        "    print(f\"Audio-transcription pairs saved to {output_file}\")\n",
        "\n",
        "# Example usage:\n",
        "folder_path = \"/kaggle/working/1\"  # Replace with the actual path to your folder\n",
        "output_folder = \"output_data\"  # Replace with your desired output folder\n",
        "process_folder(folder_path, output_folder)\n",
        "\n",
        "# Load the saved JSON file\n",
        "output_file = os.path.join(output_folder, \"audio_transcription_pairs.json\")\n",
        "with open(output_file, \"r\") as f:\n",
        "    pairs = json.load(f)\n",
        "\n",
        "# Now you have a list of dictionaries, each containing audio and transcription data\n",
        "for pair in pairs:\n",
        "    print(\"Audio path:\", pair['audio']['path'])\n",
        "    print(\"Transcription:\", pair['transcription'])\n",
        "    print(\"-\" * 20)'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T17:36:16.680793Z",
          "iopub.status.idle": "2024-10-22T17:36:16.681147Z",
          "shell.execute_reply.started": "2024-10-22T17:36:16.680967Z",
          "shell.execute_reply": "2024-10-22T17:36:16.680986Z"
        },
        "trusted": true,
        "id": "Ehb9gZvfdvSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_files_to_new_folder(source_dir, dest_dir):\n",
        "  \"\"\"Copies files from numbered folders (1, 2, 3...) in the source directory\n",
        "  to a new destination directory.\n",
        "\n",
        "  Args:\n",
        "    source_dir: The path to the directory containing the numbered folders.\n",
        "    dest_dir: The path to the new directory where files will be copied.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create the destination directory if it doesn't exist\n",
        "  os.makedirs(dest_dir, exist_ok=True)\n",
        "\n",
        "  for folder_name in os.listdir(source_dir):\n",
        "    folder_path = os.path.join(source_dir, folder_name)\n",
        "\n",
        "    # Check if it's a directory (and you might want to add a check if it's a number)\n",
        "    # Check if it's a directory AND if the folder name is a number\n",
        "    if os.path.isdir(folder_path) and folder_name.isdigit():\n",
        "      for filename in os.listdir(folder_path):\n",
        "        source_file = os.path.join(folder_path, filename)\n",
        "        destination_file = os.path.join(dest_dir, filename)\n",
        "\n",
        "        # Copy the file to the destination directory\n",
        "        shutil.copy2(source_file, destination_file)\n",
        "\n",
        "# Set the source and destination directories\n",
        "source_directory = '/kaggle/working'\n",
        "destination_directory = '/kaggle/working/all_files'  # Create a new folder named 'all_files'\n",
        "\n",
        "# Copy the files\n",
        "copy_files_to_new_folder(source_directory, destination_directory)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:27:31.770892Z",
          "iopub.execute_input": "2024-10-22T19:27:31.771549Z",
          "iopub.status.idle": "2024-10-22T19:27:33.918583Z",
          "shell.execute_reply.started": "2024-10-22T19:27:31.77151Z",
          "shell.execute_reply": "2024-10-22T19:27:33.917625Z"
        },
        "trusted": true,
        "id": "vAIChuptdvSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "def create_metadata_csv(folder_path, output_csv):\n",
        "  \"\"\"\n",
        "  Creates a metadata.csv file with the given structure for .wav files in a folder.\n",
        "\n",
        "  Args:\n",
        "    folder_path: The path to the folder containing the .wav files.\n",
        "    output_csv: The path to the output metadata.csv file.\n",
        "  \"\"\"\n",
        "\n",
        "  with open(output_csv, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"file_name\", \"transcription\"])  # Write header row\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "      if filename.endswith(\".wav\"):\n",
        "        wav_file_path = os.path.join(\"data\", filename)  # Construct the 'data/...' path\n",
        "        transcript_file_path = os.path.join(folder_path, filename.replace(\".wav\", \".txt\"))\n",
        "\n",
        "        if os.path.exists(transcript_file_path):\n",
        "          with open(transcript_file_path, \"r\") as f:\n",
        "            transcription = f.read()\n",
        "          writer.writerow([wav_file_path, transcription])\n",
        "        else:\n",
        "          print(f\"Warning: No corresponding transcript found for {filename}\")\n",
        "\n",
        "# Example usage:\n",
        "folder_path = \"/kaggle/working/all_files\"  # Replace with the actual path to your folder\n",
        "output_csv = \"metadata1-40.csv\"\n",
        "create_metadata_csv(folder_path, output_csv)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:30:26.212267Z",
          "iopub.execute_input": "2024-10-22T19:30:26.213525Z",
          "iopub.status.idle": "2024-10-22T19:30:26.4935Z",
          "shell.execute_reply.started": "2024-10-22T19:30:26.213469Z",
          "shell.execute_reply": "2024-10-22T19:30:26.492629Z"
        },
        "trusted": true,
        "id": "pWUYqLggdvSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/kaggle/working/metadata1-40.csv')\n",
        "print(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:30:46.635646Z",
          "iopub.execute_input": "2024-10-22T19:30:46.636369Z",
          "iopub.status.idle": "2024-10-22T19:30:46.672762Z",
          "shell.execute_reply.started": "2024-10-22T19:30:46.636328Z",
          "shell.execute_reply": "2024-10-22T19:30:46.671755Z"
        },
        "trusted": true,
        "id": "poxi_P25dvSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def organize_audio_data(source_folder, dest_folder=\"data\"):\n",
        "  \"\"\"\n",
        "  Organizes audio data by creating a new folder named 'data' and copying .wav files into it.\n",
        "\n",
        "  Args:\n",
        "    source_folder: The path to the folder containing the .wav and .txt files.\n",
        "    dest_folder: The name of the new folder to create (default: \"data\").\n",
        "  \"\"\"\n",
        "\n",
        "  # Create the destination folder if it doesn't exist\n",
        "  os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "  for filename in os.listdir(source_folder):\n",
        "    if filename.endswith('.wav'):\n",
        "      source_path = os.path.join(source_folder, filename)\n",
        "      dest_path = os.path.join(dest_folder, filename)\n",
        "      shutil.copy2(source_path, dest_path)  # Copy the .wav file to the data folder\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  source_folder = '/kaggle/working/all_files'  # Replace with the actual path to your folder\n",
        "  organize_audio_data(source_folder)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:31:14.45664Z",
          "iopub.execute_input": "2024-10-22T19:31:14.457394Z",
          "iopub.status.idle": "2024-10-22T19:31:15.79831Z",
          "shell.execute_reply.started": "2024-10-22T19:31:14.457355Z",
          "shell.execute_reply": "2024-10-22T19:31:15.797496Z"
        },
        "trusted": true,
        "id": "ZIVNQMfsdvSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree('/kaggle/working/my_dataset')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T17:36:16.687517Z",
          "iopub.status.idle": "2024-10-22T17:36:16.687956Z",
          "shell.execute_reply.started": "2024-10-22T17:36:16.687745Z",
          "shell.execute_reply": "2024-10-22T17:36:16.687766Z"
        },
        "trusted": true,
        "id": "0W0A1JIPdvSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def create_dataset_structure(base_dir):\n",
        "  \"\"\"\n",
        "  Creates the dataset directory structure in the specified base directory.\n",
        "\n",
        "  Args:\n",
        "    base_dir: The base directory where the structure will be created.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create the main dataset directory\n",
        "  dataset_dir = os.path.join(base_dir, \"my_dataset\")\n",
        "  os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "  # Create subdirectories\n",
        "  os.makedirs(os.path.join(dataset_dir, \"data\"), exist_ok=True)\n",
        "\n",
        "  # Create README.md file\n",
        "  readme_path = os.path.join(dataset_dir, \"README.md\")\n",
        "  with open(readme_path, \"w\") as f:\n",
        "    f.write(\"# My Dataset\\n\\nThis is a description of my dataset.\\n\")\n",
        "\n",
        "  # Create metadata.csv file (you can populate this later)\n",
        "  metadata_path = os.path.join(dataset_dir, \"metadata.csv\")\n",
        "  with open(metadata_path, \"w\") as f:\n",
        "    f.write(\"file,transcription\\n\")  # Add header row\n",
        "\n",
        "# Example usage in Kaggle:\n",
        "base_dir = \"/kaggle/working\"\n",
        "create_dataset_structure(base_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:31:24.26606Z",
          "iopub.execute_input": "2024-10-22T19:31:24.267081Z",
          "iopub.status.idle": "2024-10-22T19:31:24.274812Z",
          "shell.execute_reply.started": "2024-10-22T19:31:24.267026Z",
          "shell.execute_reply": "2024-10-22T19:31:24.273926Z"
        },
        "trusted": true,
        "id": "E0tTx7jqdvSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def move_data_to_dataset(source_dir, target_dir):\n",
        "  \"\"\"\n",
        "  Moves the contents of the source directory to the target directory.\n",
        "\n",
        "  Args:\n",
        "    source_dir: The path to the source directory (/kaggle/working/data).\n",
        "    target_dir: The path to the target directory (/kaggle/working/my_dataset/data).\n",
        "  \"\"\"\n",
        "\n",
        "  # Create the target directory if it doesn't exist\n",
        "  os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "  for filename in os.listdir(source_dir):\n",
        "    source_path = os.path.join(source_dir, filename)\n",
        "    target_path = os.path.join(target_dir, filename)\n",
        "\n",
        "    # Move the file\n",
        "    shutil.move(source_path, target_path)\n",
        "\n",
        "# Example usage in Kaggle:\n",
        "source_dir = \"/kaggle/working/data\"\n",
        "target_dir = \"/kaggle/working/my_dataset/data\"\n",
        "move_data_to_dataset(source_dir, target_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:32:34.415687Z",
          "iopub.execute_input": "2024-10-22T19:32:34.416387Z",
          "iopub.status.idle": "2024-10-22T19:32:34.606903Z",
          "shell.execute_reply.started": "2024-10-22T19:32:34.416346Z",
          "shell.execute_reply": "2024-10-22T19:32:34.6059Z"
        },
        "trusted": true,
        "id": "YudBCZ75dvSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "def move_metadata_to_dataset(source_path, target_path):\n",
        "  \"\"\"\n",
        "  Moves the metadata.csv file to the target directory.\n",
        "\n",
        "  Args:\n",
        "    source_path: The path to the source metadata.csv file (/kaggle/working/metadata.csv).\n",
        "    target_path: The path to the target metadata.csv file (/kaggle/working/my_dataset/metadata.csv).\n",
        "  \"\"\"\n",
        "\n",
        "  shutil.move(source_path, target_path)\n",
        "\n",
        "# Example usage in Kaggle:\n",
        "source_path = \"/kaggle/working/metadata1-40.csv\"\n",
        "target_path = \"/kaggle/working/my_dataset/metadata.csv\"\n",
        "move_metadata_to_dataset(source_path, target_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:33:05.920458Z",
          "iopub.execute_input": "2024-10-22T19:33:05.92133Z",
          "iopub.status.idle": "2024-10-22T19:33:05.926497Z",
          "shell.execute_reply.started": "2024-10-22T19:33:05.921287Z",
          "shell.execute_reply": "2024-10-22T19:33:05.925625Z"
        },
        "trusted": true,
        "id": "EMR68h1IdvSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"audiofolder\", data_dir=\"/kaggle/working/my_dataset\")\n",
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:33:16.396927Z",
          "iopub.execute_input": "2024-10-22T19:33:16.397319Z",
          "iopub.status.idle": "2024-10-22T19:33:40.132779Z",
          "shell.execute_reply.started": "2024-10-22T19:33:16.397278Z",
          "shell.execute_reply": "2024-10-22T19:33:40.132026Z"
        },
        "trusted": true,
        "id": "lYF0Po7rdvSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:33:50.982263Z",
          "iopub.execute_input": "2024-10-22T19:33:50.983447Z",
          "iopub.status.idle": "2024-10-22T19:34:03.018072Z",
          "shell.execute_reply.started": "2024-10-22T19:33:50.983401Z",
          "shell.execute_reply": "2024-10-22T19:34:03.016997Z"
        },
        "trusted": true,
        "id": "2hdtXItTdvSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:34:03.020185Z",
          "iopub.execute_input": "2024-10-22T19:34:03.020503Z",
          "iopub.status.idle": "2024-10-22T19:34:14.688986Z",
          "shell.execute_reply.started": "2024-10-22T19:34:03.02047Z",
          "shell.execute_reply": "2024-10-22T19:34:14.687824Z"
        },
        "trusted": true,
        "id": "OP0u1B-ldvSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:34:14.690626Z",
          "iopub.execute_input": "2024-10-22T19:34:14.691062Z",
          "iopub.status.idle": "2024-10-22T19:34:14.720027Z",
          "shell.execute_reply.started": "2024-10-22T19:34:14.691014Z",
          "shell.execute_reply": "2024-10-22T19:34:14.719126Z"
        },
        "trusted": true,
        "id": "KeagDF8IdvSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.push_to_hub(\"Shabdobhedi/english_technical\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:34:57.86192Z",
          "iopub.execute_input": "2024-10-22T19:34:57.862753Z",
          "iopub.status.idle": "2024-10-22T19:35:23.076551Z",
          "shell.execute_reply.started": "2024-10-22T19:34:57.862711Z",
          "shell.execute_reply": "2024-10-22T19:35:23.07565Z"
        },
        "trusted": true,
        "id": "ZijCMUYedvSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_files_in_folders(directory):\n",
        "  \"\"\"Counts the total number of files in numbered folders (1-24) within a directory.\n",
        "\n",
        "  Args:\n",
        "    directory: The path to the directory containing the numbered folders.\n",
        "\n",
        "  Returns:\n",
        "    The total number of files found in the folders.\n",
        "  \"\"\"\n",
        "\n",
        "  total_files = 0\n",
        "  for i in range(1, 40):  # Loop through folders 1 to 24\n",
        "    folder_path = os.path.join(directory, str(i))\n",
        "    if os.path.isdir(folder_path):\n",
        "      total_files += len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "  return total_files\n",
        "\n",
        "# Get the directory path (replace with your actual directory)\n",
        "directory = '/kaggle/working'\n",
        "\n",
        "# Count the files\n",
        "file_count = count_files_in_folders(directory)\n",
        "print(f\"Total files in folders 1-24: {file_count}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:21:49.515562Z",
          "iopub.execute_input": "2024-10-22T19:21:49.515967Z",
          "iopub.status.idle": "2024-10-22T19:21:49.609299Z",
          "shell.execute_reply.started": "2024-10-22T19:21:49.515927Z",
          "shell.execute_reply": "2024-10-22T19:21:49.608395Z"
        },
        "trusted": true,
        "id": "sRLujPF6dvSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"Shabdobhedi/english_technical\", split =\"train\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:37:19.142072Z",
          "iopub.execute_input": "2024-10-22T19:37:19.142472Z",
          "iopub.status.idle": "2024-10-22T19:37:19.882419Z",
          "shell.execute_reply.started": "2024-10-22T19:37:19.14243Z",
          "shell.execute_reply": "2024-10-22T19:37:19.881526Z"
        },
        "trusted": true,
        "id": "9aPGWdZadvSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:37:23.692115Z",
          "iopub.execute_input": "2024-10-22T19:37:23.693106Z",
          "iopub.status.idle": "2024-10-22T19:37:23.69787Z",
          "shell.execute_reply.started": "2024-10-22T19:37:23.693046Z",
          "shell.execute_reply": "2024-10-22T19:37:23.696707Z"
        },
        "trusted": true,
        "id": "l666tg1_dvSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ds)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-22T19:37:26.517144Z",
          "iopub.execute_input": "2024-10-22T19:37:26.517533Z",
          "iopub.status.idle": "2024-10-22T19:37:26.523836Z",
          "shell.execute_reply.started": "2024-10-22T19:37:26.517493Z",
          "shell.execute_reply": "2024-10-22T19:37:26.522954Z"
        },
        "trusted": true,
        "id": "-YTltx7udvSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-PopXjyfdvSe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}